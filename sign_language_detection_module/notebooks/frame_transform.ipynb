{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fb36c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8899c4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FramesToNpyConverter:\n",
    "    def __init__(self, seq_len=37, max_hands=2):\n",
    "        self.seq_len = seq_len\n",
    "        self.max_hands = max_hands\n",
    "        self.landmark_dim = 21 * 3 * max_hands\n",
    "\n",
    "        mp_hands = mp.solutions.hands\n",
    "        self.hands = mp_hands.Hands(\n",
    "            static_image_mode=True,\n",
    "            max_num_hands=max_hands,\n",
    "            min_detection_confidence=0.6\n",
    "        )\n",
    "\n",
    "    def extract_landmarks(self, image):\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = self.hands.process(image_rgb)\n",
    "\n",
    "        if not results.multi_hand_landmarks:\n",
    "            return np.zeros(self.landmark_dim, dtype=np.float32)\n",
    "\n",
    "        coords = []\n",
    "\n",
    "        for hand in results.multi_hand_landmarks[: self.max_hands]:\n",
    "            for lm in hand.landmark:\n",
    "                coords.extend([lm.x, lm.y, lm.z])\n",
    "\n",
    "        # pad missing hands\n",
    "        missing = self.max_hands - len(results.multi_hand_landmarks)\n",
    "        if missing > 0:\n",
    "            coords.extend([0.0] * missing * 21 * 3)\n",
    "\n",
    "        return np.array(coords, dtype=np.float32)\n",
    "\n",
    "    def frames_folder_to_npy(self, frames_dir):\n",
    "        frame_files = sorted(\n",
    "            f for f in os.listdir(frames_dir)\n",
    "            if f.lower().endswith((\".jpg\", \".png\"))\n",
    "        )\n",
    "\n",
    "        sequence = []\n",
    "\n",
    "        for f in frame_files:\n",
    "            img = cv2.imread(os.path.join(frames_dir, f))\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            sequence.append(self.extract_landmarks(img))\n",
    "\n",
    "        # handle rare edge cases\n",
    "        if len(sequence) == 0:\n",
    "            return np.zeros((self.seq_len, self.landmark_dim), dtype=np.float32)\n",
    "\n",
    "        if len(sequence) != self.seq_len:\n",
    "            idx = np.linspace(0, len(sequence) - 1, self.seq_len).astype(int)\n",
    "            sequence = [sequence[i] for i in idx]\n",
    "\n",
    "        return np.stack(sequence)\n",
    "\n",
    "    def save(self, frames_dir, output_dir):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        seq = self.frames_folder_to_npy(frames_dir)\n",
    "\n",
    "        video_name = os.path.basename(frames_dir.rstrip(\"/\"))\n",
    "        out_path = os.path.join(output_dir, video_name + \".npy\")\n",
    "\n",
    "        np.save(out_path, seq)\n",
    "        return out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141ebbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 168 video folders under data\\SL_frames_output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting: 100%|██████████| 168/168 [03:48<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Errors: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "FRAMES_ROOT = Path(r\"data\\\\SL_frames_output\")\n",
    "NPY_OUTPUT  = Path(r\"data\\\\SL_12_classes_npy\")  \n",
    "NPY_OUTPUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "converter = FramesToNpyConverter(seq_len=37, max_hands=2)\n",
    "\n",
    "# collect all video folders: class/video_id\n",
    "video_dirs = []\n",
    "for class_dir in FRAMES_ROOT.iterdir():\n",
    "    if not class_dir.is_dir():\n",
    "        continue\n",
    "    for vid_dir in class_dir.iterdir():\n",
    "        if vid_dir.is_dir():\n",
    "            video_dirs.append(vid_dir)\n",
    "\n",
    "print(f\"Found {len(video_dirs)} video folders under {FRAMES_ROOT}\")\n",
    "\n",
    "errors = []\n",
    "for vid_dir in tqdm(video_dirs, desc=\"Converting\"):\n",
    "    class_name = vid_dir.parent.name\n",
    "    out_dir = NPY_OUTPUT / class_name\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        converter.save(str(vid_dir), str(out_dir))\n",
    "    except Exception as e:\n",
    "        errors.append((str(vid_dir), str(e)))\n",
    "\n",
    "print(f\"Done. Errors: {len(errors)}\")\n",
    "if errors:\n",
    "    print(\"First few errors:\")\n",
    "    for p, msg in errors[:10]:\n",
    "        print(\" -\", p, \"->\", msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1d6a1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done flattening: data\\SL_12_classes_npy\n"
     ]
    }
   ],
   "source": [
    "ROOT = Path(r\"data\\SL_12_classes_npy\")  # folder that currently has subfolders\n",
    "\n",
    "# Move all npy files from subfolders into ROOT\n",
    "for subdir in [p for p in ROOT.iterdir() if p.is_dir()]:\n",
    "    class_name = subdir.name\n",
    "    for npy_path in subdir.rglob(\"*.npy\"):\n",
    "        # rename to avoid collisions: e.g., bed_05629.npy\n",
    "        new_name = f\"{class_name}_{npy_path.name}\"\n",
    "        dest = ROOT / new_name\n",
    "\n",
    "        # if you prefer overwrite, replace this check with: dest.unlink(missing_ok=True)\n",
    "        if dest.exists():\n",
    "            raise FileExistsError(f\"Collision: {dest} already exists\")\n",
    "\n",
    "        shutil.move(str(npy_path), str(dest))\n",
    "\n",
    "# Remove empty subfolders (deepest first)\n",
    "for d in sorted([p for p in ROOT.rglob(\"*\") if p.is_dir()], key=lambda x: len(x.parts), reverse=True):\n",
    "    try:\n",
    "        d.rmdir()  # only removes if empty\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "print(\"Done flattening:\", ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9650de7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6218/6218 [1:28:44<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "FRAMES_ROOT = \"data\\\\jester_2_classes\"\n",
    "NPY_OUTPUT  = \"data\\\\jester_2_classes_npy\"\n",
    "\n",
    "converter = FramesToNpyConverter(seq_len=37, max_hands=2)\n",
    "os.makedirs(NPY_OUTPUT, exist_ok=True)\n",
    "\n",
    "for video_folder in tqdm(os.listdir(FRAMES_ROOT)):\n",
    "    frames_dir = os.path.join(FRAMES_ROOT, video_folder)\n",
    "    if not os.path.isdir(frames_dir):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        converter.save(frames_dir, NPY_OUTPUT)\n",
    "    except Exception as e:\n",
    "        print(\"ERROR:\", frames_dir, e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77fd3fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting files...\n",
      "Total samples: 6386\n",
      "YES class: 168 files\n",
      "NO class: 6218 files\n",
      "\n",
      "======================================================================\n",
      "Dataset Split Summary (80% Train / 10% Val / 10% Test):\n",
      "======================================================================\n",
      "TRAIN: YES= 134 ( 79.8%), NO=4974 ( 80.0%), Total= 5108\n",
      "VAL  : YES=  17 ( 10.1%), NO= 622 ( 10.0%), Total=  639\n",
      "TEST : YES=  17 ( 10.1%), NO= 622 ( 10.0%), Total=  639\n",
      "======================================================================\n",
      "\n",
      "CSV files saved to: data\\splits\n"
     ]
    }
   ],
   "source": [
    "SL_NPY = \"data\\\\SL_12_classes_npy\"\n",
    "JESTER_NPY = \"data\\\\jester_NO_npy\"\n",
    "\n",
    "SPLITS_DIR = \"data\\\\splits\"\n",
    "os.makedirs(SPLITS_DIR, exist_ok=True)\n",
    "\n",
    "TRAIN_RATIO = 0.8\n",
    "VAL_RATIO = 0.1\n",
    "TEST_RATIO = 0.1\n",
    "\n",
    "def collect_files_with_labels(root_dir, class_name, label):\n",
    "    \"\"\"Collect all .npy files with their class and label.\"\"\"\n",
    "    files = list(Path(root_dir).rglob(\"*.npy\"))\n",
    "    data = []\n",
    "    for f in files:\n",
    "        data.append({\n",
    "            'filepath': str(f),\n",
    "            'class': class_name,\n",
    "            'label': label\n",
    "        })\n",
    "    return data\n",
    "\n",
    "def create_split_csvs(yes_data, no_data, splits_dir):\n",
    "    \"\"\"Create train/val/test CSV files.\"\"\"\n",
    "    \n",
    "    # Combine and create DataFrame\n",
    "    all_data = yes_data + no_data\n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    print(f\"Total samples: {len(df)}\")\n",
    "    print(f\"YES class: {len(yes_data)} files\")\n",
    "    print(f\"NO class: {len(no_data)} files\")\n",
    "    \n",
    "    # Split by class for stratification\n",
    "    yes_df = df[df['class'] == 'yes']\n",
    "    no_df = df[df['class'] == 'no']\n",
    "    \n",
    "    # Split YES class\n",
    "    yes_train, yes_temp = train_test_split(\n",
    "        yes_df, \n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    yes_val, yes_test = train_test_split(\n",
    "        yes_temp, \n",
    "        test_size=0.5,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Split NO class\n",
    "    no_train, no_temp = train_test_split(\n",
    "        no_df, \n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    no_val, no_test = train_test_split(\n",
    "        no_temp, \n",
    "        test_size=0.5,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    train_df = pd.concat([yes_train, no_train]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    val_df = pd.concat([yes_val, no_val]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    test_df = pd.concat([yes_test, no_test]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    train_df.to_csv(os.path.join(splits_dir, 'train.csv'), index=False)\n",
    "    val_df.to_csv(os.path.join(splits_dir, 'val.csv'), index=False)\n",
    "    test_df.to_csv(os.path.join(splits_dir, 'test.csv'), index=False)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Dataset Split Summary (80% Train / 10% Val / 10% Test):\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for split_name, split_df in [('TRAIN', train_df), ('VAL', val_df), ('TEST', test_df)]:\n",
    "        yes_count = len(split_df[split_df['class'] == 'yes'])\n",
    "        no_count = len(split_df[split_df['class'] == 'no'])\n",
    "        total = len(split_df)\n",
    "        yes_pct = (yes_count / len(yes_df)) * 100\n",
    "        no_pct = (no_count / len(no_df)) * 100\n",
    "        print(f\"{split_name:5s}: YES={yes_count:4d} ({yes_pct:5.1f}%), \"\n",
    "              f\"NO={no_count:4d} ({no_pct:5.1f}%), Total={total:5d}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nCSV files saved to: {splits_dir}\")\n",
    "\n",
    "# Collect files with labels\n",
    "print(\"Collecting files...\")\n",
    "yes_data = collect_files_with_labels(SL_NPY, 'yes', 1)\n",
    "no_data = collect_files_with_labels(JESTER_NPY, 'no', 0)\n",
    "\n",
    "# Create split CSVs\n",
    "create_split_csvs(yes_data, no_data, SPLITS_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semcom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
